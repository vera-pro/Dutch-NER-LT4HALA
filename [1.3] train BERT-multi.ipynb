{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments, AutoModel\n",
    "from datasets import load_dataset, load_metric, Dataset, DatasetDict\n",
    "import numpy as np\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import prepare_data, convert_to_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb54a49ab68744f098cf3662d214e94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3991a77aa64536b4718e175bf63800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e56145056594b7fa4badafef649bdbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "train = prepare_data('/ivi/ilps/personal/vprovat/KB/data/AITrainingset/Data/train.txt')\n",
    "val = prepare_data('/ivi/ilps/personal/vprovat/KB/data/AITrainingset/Data/validation.txt')\n",
    "test_VOC = prepare_data('/ivi/ilps/personal/vprovat/KB/data/AITrainingset/Data/test_VOC.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = sorted(list(set([token_data[1] for sentence in train for token_data in sentence if token_data])))\n",
    "label_map = {label: i for i, label in enumerate(label_list)}\n",
    "id2label = {i: label for i, label in enumerate(label_list)}\n",
    "label2id = {label: i for i, label in enumerate(label_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = convert_to_dataset(train, label_map)\n",
    "val_data = convert_to_dataset(val, label_map)\n",
    "test_data = convert_to_dataset(test_VOC, label_map)\n",
    "\n",
    "datasets = DatasetDict({\n",
    "    \"train\": train_data,\n",
    "    \"validation\": val_data,\n",
    "    \"test\": test_data,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_prediction):\n",
    "    predictions, labels = eval_prediction\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision_score(true_labels, true_predictions),\n",
    "        \"recall\": recall_score(true_labels, true_predictions),\n",
    "        \"f1\": f1_score(true_labels, true_predictions),\n",
    "        \"classification_report\": classification_report(true_labels, true_predictions),\n",
    "    }\n",
    "\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True, padding=True\n",
    "    )\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "197ade8fc4114c9e999eef564a8b08cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71c0db8bac641bfaac398a4844a0e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa9322b423b8497d83e258ef43a6c2d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fe256994d94d3ca2f272acb45d4e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ace8cd839b49cebf7e8ef65fc304ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# model_name = \"/ivi/ilps/personal/vprovat/KB/GysBERT\"\n",
    "# model_name = \"GroNLP/bert-base-dutch-cased\"\n",
    "model_name = \"bert-base-cased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name,num_labels=len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11104 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2761 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/111 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback, IntervalStrategy\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/ivi/ilps/personal/vprovat/KB/NER_logs_BERT-multi-cased\", #change here\n",
    "    evaluation_strategy=IntervalStrategy.STEPS, #\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_steps=100,\n",
    "    save_total_limit = 50,\n",
    "    learning_rate=5e-5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collator(data):\n",
    "    input_ids = [torch.tensor(item[\"input_ids\"]) for item in data]\n",
    "    attention_mask = [torch.tensor(item[\"attention_mask\"]) for item in data]\n",
    "    labels = [torch.tensor(item[\"labels\"]) for item in data]\n",
    "\n",
    "\n",
    "    input_ids = torch.nn.utils.rnn.pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    attention_mask = torch.nn.utils.rnn.pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=-100)\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels,\n",
    "    }\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vprovat/anaconda3/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvsprovatorova\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/vprovat/KB_NER/wandb/run-20230823_185257-jod2722t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vsprovatorova/huggingface/runs/jod2722t' target=\"_blank\">morning-eon-13</a></strong> to <a href='https://wandb.ai/vsprovatorova/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vsprovatorova/huggingface' target=\"_blank\">https://wandb.ai/vsprovatorova/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vsprovatorova/huggingface/runs/jod2722t' target=\"_blank\">https://wandb.ai/vsprovatorova/huggingface/runs/jod2722t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6500' max='20820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6500/20820 1:37:26 < 3:34:43, 1.11 it/s, Epoch 4/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Classification Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.133400</td>\n",
       "      <td>0.132026</td>\n",
       "      <td>0.583432</td>\n",
       "      <td>0.615314</td>\n",
       "      <td>0.598949</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.56      0.73      0.64      6988\n",
       "         PER       0.62      0.58      0.60     13330\n",
       "        TIME       0.52      0.53      0.52      4588\n",
       "\n",
       "   micro avg       0.58      0.62      0.60     24906\n",
       "   macro avg       0.57      0.61      0.59     24906\n",
       "weighted avg       0.59      0.62      0.60     24906\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.122300</td>\n",
       "      <td>0.114149</td>\n",
       "      <td>0.625261</td>\n",
       "      <td>0.649161</td>\n",
       "      <td>0.636987</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.73      0.71      0.72      6988\n",
       "         PER       0.59      0.64      0.61     13330\n",
       "        TIME       0.58      0.58      0.58      4588\n",
       "\n",
       "   micro avg       0.63      0.65      0.64     24906\n",
       "   macro avg       0.63      0.64      0.64     24906\n",
       "weighted avg       0.63      0.65      0.64     24906\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>0.109193</td>\n",
       "      <td>0.645037</td>\n",
       "      <td>0.665342</td>\n",
       "      <td>0.655032</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.71      0.75      0.73      6988\n",
       "         PER       0.64      0.65      0.64     13330\n",
       "        TIME       0.55      0.59      0.57      4588\n",
       "\n",
       "   micro avg       0.65      0.67      0.66     24906\n",
       "   macro avg       0.64      0.66      0.65     24906\n",
       "weighted avg       0.65      0.67      0.66     24906\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.095400</td>\n",
       "      <td>0.101876</td>\n",
       "      <td>0.669386</td>\n",
       "      <td>0.662290</td>\n",
       "      <td>0.665819</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.72      0.76      0.74      6988\n",
       "         PER       0.66      0.63      0.65     13330\n",
       "        TIME       0.60      0.61      0.61      4588\n",
       "\n",
       "   micro avg       0.67      0.66      0.67     24906\n",
       "   macro avg       0.66      0.67      0.66     24906\n",
       "weighted avg       0.67      0.66      0.67     24906\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>0.097988</td>\n",
       "      <td>0.674522</td>\n",
       "      <td>0.676905</td>\n",
       "      <td>0.675711</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.71      0.77      0.74      6988\n",
       "         PER       0.68      0.65      0.66     13330\n",
       "        TIME       0.61      0.62      0.61      4588\n",
       "\n",
       "   micro avg       0.67      0.68      0.68     24906\n",
       "   macro avg       0.67      0.68      0.67     24906\n",
       "weighted avg       0.67      0.68      0.67     24906\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.077200</td>\n",
       "      <td>0.103555</td>\n",
       "      <td>0.656686</td>\n",
       "      <td>0.693046</td>\n",
       "      <td>0.674376</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.72      0.77      0.74      6988\n",
       "         PER       0.64      0.67      0.66     13330\n",
       "        TIME       0.60      0.63      0.62      4588\n",
       "\n",
       "   micro avg       0.66      0.69      0.67     24906\n",
       "   macro avg       0.65      0.69      0.67     24906\n",
       "weighted avg       0.66      0.69      0.67     24906\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.080200</td>\n",
       "      <td>0.095889</td>\n",
       "      <td>0.697104</td>\n",
       "      <td>0.675580</td>\n",
       "      <td>0.686173</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.76      0.75      0.76      6988\n",
       "         PER       0.70      0.65      0.67     13330\n",
       "        TIME       0.61      0.63      0.62      4588\n",
       "\n",
       "   micro avg       0.70      0.68      0.69     24906\n",
       "   macro avg       0.69      0.68      0.68     24906\n",
       "weighted avg       0.70      0.68      0.69     24906\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.075600</td>\n",
       "      <td>0.094798</td>\n",
       "      <td>0.701150</td>\n",
       "      <td>0.672970</td>\n",
       "      <td>0.686771</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.79      0.73      0.76      6988\n",
       "         PER       0.69      0.66      0.68     13330\n",
       "        TIME       0.61      0.62      0.62      4588\n",
       "\n",
       "   micro avg       0.70      0.67      0.69     24906\n",
       "   macro avg       0.70      0.67      0.68     24906\n",
       "weighted avg       0.70      0.67      0.69     24906\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.100108</td>\n",
       "      <td>0.708750</td>\n",
       "      <td>0.679354</td>\n",
       "      <td>0.693741</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.78      0.75      0.76      6988\n",
       "         PER       0.70      0.66      0.68     13330\n",
       "        TIME       0.62      0.63      0.63      4588\n",
       "\n",
       "   micro avg       0.71      0.68      0.69     24906\n",
       "   macro avg       0.70      0.68      0.69     24906\n",
       "weighted avg       0.71      0.68      0.69     24906\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.059500</td>\n",
       "      <td>0.096935</td>\n",
       "      <td>0.714927</td>\n",
       "      <td>0.684413</td>\n",
       "      <td>0.699337</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.78      0.75      0.76      6988\n",
       "         PER       0.71      0.67      0.69     13330\n",
       "        TIME       0.64      0.63      0.63      4588\n",
       "\n",
       "   micro avg       0.71      0.68      0.70     24906\n",
       "   macro avg       0.71      0.68      0.69     24906\n",
       "weighted avg       0.72      0.68      0.70     24906\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.061400</td>\n",
       "      <td>0.095124</td>\n",
       "      <td>0.713885</td>\n",
       "      <td>0.684132</td>\n",
       "      <td>0.698692</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.78      0.76      0.77      6988\n",
       "         PER       0.71      0.67      0.69     13330\n",
       "        TIME       0.63      0.62      0.63      4588\n",
       "\n",
       "   micro avg       0.71      0.68      0.70     24906\n",
       "   macro avg       0.71      0.68      0.69     24906\n",
       "weighted avg       0.71      0.68      0.70     24906\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.048400</td>\n",
       "      <td>0.099664</td>\n",
       "      <td>0.692439</td>\n",
       "      <td>0.699028</td>\n",
       "      <td>0.695718</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.75      0.78      0.77      6988\n",
       "         PER       0.69      0.68      0.68     13330\n",
       "        TIME       0.61      0.63      0.62      4588\n",
       "\n",
       "   micro avg       0.69      0.70      0.70     24906\n",
       "   macro avg       0.68      0.70      0.69     24906\n",
       "weighted avg       0.69      0.70      0.70     24906\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.051400</td>\n",
       "      <td>0.100486</td>\n",
       "      <td>0.708220</td>\n",
       "      <td>0.687063</td>\n",
       "      <td>0.697481</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.78      0.75      0.76      6988\n",
       "         PER       0.70      0.68      0.69     13330\n",
       "        TIME       0.64      0.63      0.63      4588\n",
       "\n",
       "   micro avg       0.71      0.69      0.70     24906\n",
       "   macro avg       0.70      0.68      0.69     24906\n",
       "weighted avg       0.71      0.69      0.70     24906\n",
       "</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.56      0.73      0.64      6988\n",
      "         PER       0.62      0.58      0.60     13330\n",
      "        TIME       0.52      0.53      0.52      4588\n",
      "\n",
      "   micro avg       0.58      0.62      0.60     24906\n",
      "   macro avg       0.57      0.61      0.59     24906\n",
      "weighted avg       0.59      0.62      0.60     24906\n",
      "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.73      0.71      0.72      6988\n",
      "         PER       0.59      0.64      0.61     13330\n",
      "        TIME       0.58      0.58      0.58      4588\n",
      "\n",
      "   micro avg       0.63      0.65      0.64     24906\n",
      "   macro avg       0.63      0.64      0.64     24906\n",
      "weighted avg       0.63      0.65      0.64     24906\n",
      "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.71      0.75      0.73      6988\n",
      "         PER       0.64      0.65      0.64     13330\n",
      "        TIME       0.55      0.59      0.57      4588\n",
      "\n",
      "   micro avg       0.65      0.67      0.66     24906\n",
      "   macro avg       0.64      0.66      0.65     24906\n",
      "weighted avg       0.65      0.67      0.66     24906\n",
      "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.72      0.76      0.74      6988\n",
      "         PER       0.66      0.63      0.65     13330\n",
      "        TIME       0.60      0.61      0.61      4588\n",
      "\n",
      "   micro avg       0.67      0.66      0.67     24906\n",
      "   macro avg       0.66      0.67      0.66     24906\n",
      "weighted avg       0.67      0.66      0.67     24906\n",
      "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.71      0.77      0.74      6988\n",
      "         PER       0.68      0.65      0.66     13330\n",
      "        TIME       0.61      0.62      0.61      4588\n",
      "\n",
      "   micro avg       0.67      0.68      0.68     24906\n",
      "   macro avg       0.67      0.68      0.67     24906\n",
      "weighted avg       0.67      0.68      0.67     24906\n",
      "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.72      0.77      0.74      6988\n",
      "         PER       0.64      0.67      0.66     13330\n",
      "        TIME       0.60      0.63      0.62      4588\n",
      "\n",
      "   micro avg       0.66      0.69      0.67     24906\n",
      "   macro avg       0.65      0.69      0.67     24906\n",
      "weighted avg       0.66      0.69      0.67     24906\n",
      "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.76      0.75      0.76      6988\n",
      "         PER       0.70      0.65      0.67     13330\n",
      "        TIME       0.61      0.63      0.62      4588\n",
      "\n",
      "   micro avg       0.70      0.68      0.69     24906\n",
      "   macro avg       0.69      0.68      0.68     24906\n",
      "weighted avg       0.70      0.68      0.69     24906\n",
      "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.79      0.73      0.76      6988\n",
      "         PER       0.69      0.66      0.68     13330\n",
      "        TIME       0.61      0.62      0.62      4588\n",
      "\n",
      "   micro avg       0.70      0.67      0.69     24906\n",
      "   macro avg       0.70      0.67      0.68     24906\n",
      "weighted avg       0.70      0.67      0.69     24906\n",
      "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.78      0.75      0.76      6988\n",
      "         PER       0.70      0.66      0.68     13330\n",
      "        TIME       0.62      0.63      0.63      4588\n",
      "\n",
      "   micro avg       0.71      0.68      0.69     24906\n",
      "   macro avg       0.70      0.68      0.69     24906\n",
      "weighted avg       0.71      0.68      0.69     24906\n",
      "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.78      0.75      0.76      6988\n",
      "         PER       0.71      0.67      0.69     13330\n",
      "        TIME       0.64      0.63      0.63      4588\n",
      "\n",
      "   micro avg       0.71      0.68      0.70     24906\n",
      "   macro avg       0.71      0.68      0.69     24906\n",
      "weighted avg       0.72      0.68      0.70     24906\n",
      "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.78      0.76      0.77      6988\n",
      "         PER       0.71      0.67      0.69     13330\n",
      "        TIME       0.63      0.62      0.63      4588\n",
      "\n",
      "   micro avg       0.71      0.68      0.70     24906\n",
      "   macro avg       0.71      0.68      0.69     24906\n",
      "weighted avg       0.71      0.68      0.70     24906\n",
      "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.75      0.78      0.77      6988\n",
      "         PER       0.69      0.68      0.68     13330\n",
      "        TIME       0.61      0.63      0.62      4588\n",
      "\n",
      "   micro avg       0.69      0.70      0.70     24906\n",
      "   macro avg       0.68      0.70      0.69     24906\n",
      "weighted avg       0.69      0.70      0.70     24906\n",
      "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.78      0.75      0.76      6988\n",
      "         PER       0.70      0.68      0.69     13330\n",
      "        TIME       0.64      0.63      0.63      4588\n",
      "\n",
      "   micro avg       0.71      0.69      0.70     24906\n",
      "   macro avg       0.70      0.68      0.69     24906\n",
      "weighted avg       0.71      0.69      0.70     24906\n",
      "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6500, training_loss=0.08687260246276855, metrics={'train_runtime': 5857.2696, 'train_samples_per_second': 28.436, 'train_steps_per_second': 3.555, 'total_flos': 1.3588045565952e+16, 'train_loss': 0.08687260246276855, 'epoch': 4.68})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.config.id2label = id2label\n",
    "trainer.model.config.label2id = label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('/ivi/ilps/personal/vprovat/KB/models/BERT-multi-cased-NER-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = trainer.predict(tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[[-0.11308523,  0.28306374, -2.5450878 , ..., -0.8496628 ,\n",
       "         -2.0836978 ,  4.238312  ],\n",
       "        [ 5.108827  ,  0.13123973, -3.0826669 , ..., -2.337807  ,\n",
       "         -3.535562  ,  2.442111  ],\n",
       "        [-0.7368386 , -3.0711036 , -2.941254  , ..., -1.3434206 ,\n",
       "         -2.6588874 ,  6.7481556 ],\n",
       "        ...,\n",
       "        [-1.2727859 , -1.6499017 , -2.8777916 , ..., -2.0274026 ,\n",
       "         -2.2507133 ,  9.080972  ],\n",
       "        [-1.2646996 , -1.7404342 , -2.8056834 , ..., -2.0401525 ,\n",
       "         -2.2040095 ,  9.123766  ],\n",
       "        [-0.23187871, -0.14783058, -2.9348915 , ..., -1.9613186 ,\n",
       "         -2.44029   ,  7.005603  ]],\n",
       "\n",
       "       [[ 0.27685595, -0.21969439, -2.2987916 , ..., -0.6269867 ,\n",
       "         -1.7885745 ,  2.8498516 ],\n",
       "        [-2.8790243 , -0.8633581 , -1.3185526 , ..., -0.717562  ,\n",
       "         -0.34523863,  5.5737166 ],\n",
       "        [-3.0382226 , -1.6483521 , -2.8082068 , ..., -0.6817659 ,\n",
       "          0.8414026 ,  5.481147  ],\n",
       "        ...,\n",
       "        [ 0.6043987 , -0.32661727, -2.5247614 , ..., -0.35345703,\n",
       "         -1.7467229 ,  2.9564083 ],\n",
       "        [ 0.5850578 , -0.42247483, -2.550008  , ..., -0.5801328 ,\n",
       "         -1.7908003 ,  3.286731  ],\n",
       "        [ 0.23384053, -0.20366596, -2.552557  , ..., -0.6316789 ,\n",
       "         -1.7058338 ,  3.3330054 ]],\n",
       "\n",
       "       [[-0.24502818, -0.4545764 , -1.7012912 , ..., -1.0665153 ,\n",
       "         -1.1119108 ,  3.5098805 ],\n",
       "        [-2.612653  , -0.92415255, -3.1370828 , ..., -1.3879856 ,\n",
       "         -2.257625  ,  8.88321   ],\n",
       "        [-2.3265364 , -1.3599192 , -2.1713216 , ..., -1.2873143 ,\n",
       "         -2.1142344 ,  9.451942  ],\n",
       "        ...,\n",
       "        [ 0.09156691,  0.06027194, -1.5210533 , ..., -2.9434612 ,\n",
       "         -2.2301185 ,  6.17048   ],\n",
       "        [ 0.18607847, -0.02457665, -0.3601265 , ..., -2.971862  ,\n",
       "         -1.8125718 ,  5.3254814 ],\n",
       "        [-0.38221434, -0.13665672, -2.5327628 , ..., -2.0528593 ,\n",
       "         -2.2731757 ,  6.6552835 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.47615707,  0.95535886, -2.7698605 , ...,  0.10639054,\n",
       "         -2.3047385 ,  3.7583537 ],\n",
       "        [-2.4137683 , -1.8197922 , -2.5043857 , ..., -1.2547592 ,\n",
       "         -2.088595  ,  9.577405  ],\n",
       "        [-1.9139572 , -2.2141225 , -1.8662382 , ..., -2.2287025 ,\n",
       "         -2.4021535 ,  9.684672  ],\n",
       "        ...,\n",
       "        [-1.5143476 , -0.7724827 , -2.7386606 , ..., -1.8466917 ,\n",
       "         -3.1624987 ,  8.879939  ],\n",
       "        [-1.9093754 , -1.7150996 , -2.1769748 , ..., -1.2226688 ,\n",
       "         -2.366661  ,  8.713918  ],\n",
       "        [-1.4496104 ,  0.95045525, -4.115987  , ...,  0.25851044,\n",
       "         -2.7959993 ,  6.9700193 ]],\n",
       "\n",
       "       [[-0.09173384,  1.2342583 , -2.2536223 , ..., -0.42372233,\n",
       "         -2.4564533 ,  3.2782564 ],\n",
       "        [-1.9492459 , -1.7119097 , -3.1694543 , ..., -1.3219591 ,\n",
       "         -2.2028608 ,  9.107722  ],\n",
       "        [-1.8196527 , -2.8510976 , -1.8856862 , ..., -1.1084744 ,\n",
       "         -1.916283  ,  8.166078  ],\n",
       "        ...,\n",
       "        [-0.36001518,  0.871946  , -3.6235635 , ..., -0.9588359 ,\n",
       "         -3.630203  ,  6.190836  ],\n",
       "        [-0.46585777, -0.47459996, -3.651962  , ..., -1.012797  ,\n",
       "         -3.925712  ,  7.6822014 ],\n",
       "        [-1.2351147 ,  1.1837382 , -4.518973  , ...,  0.43775082,\n",
       "         -3.286735  ,  6.8392234 ]],\n",
       "\n",
       "       [[ 0.37094462, -0.19116361, -1.6695744 , ..., -0.766695  ,\n",
       "         -1.3483032 ,  2.7228854 ],\n",
       "        [-1.015793  ,  4.7101626 , -2.9594524 , ..., -0.1761912 ,\n",
       "         -2.650672  ,  3.1666589 ],\n",
       "        [-1.9153028 ,  1.2397436 , -2.9456937 , ...,  3.9296534 ,\n",
       "         -2.3168569 ,  2.165247  ],\n",
       "        ...,\n",
       "        [-0.60246885,  0.06255087, -2.7356532 , ..., -1.9483782 ,\n",
       "         -2.3764508 ,  7.2820845 ],\n",
       "        [-0.8840589 , -0.36419725, -2.6013567 , ..., -2.0153964 ,\n",
       "         -2.2209153 ,  7.6705856 ],\n",
       "        [ 0.18635294,  0.7623434 , -1.9583771 , ..., -1.5886796 ,\n",
       "         -1.7748729 ,  4.72733   ]]], dtype=float32), label_ids=array([[-100,    0,    6, ..., -100, -100, -100],\n",
       "       [-100,    6,    6, ..., -100, -100, -100],\n",
       "       [-100,    6, -100, ..., -100, -100, -100],\n",
       "       ...,\n",
       "       [-100,    6, -100, ..., -100, -100, -100],\n",
       "       [-100,    6,    6, ..., -100, -100, -100],\n",
       "       [-100,    1,    4, ..., -100, -100, -100]]), metrics={'test_loss': 0.09862799942493439, 'test_precision': 0.657258064516129, 'test_recall': 0.6468253968253969, 'test_f1': 0.652, 'test_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.78      0.76      0.77       307\\n         PER       0.53      0.51      0.52       272\\n        TIME       0.64      0.66      0.65       177\\n\\n   micro avg       0.66      0.65      0.65       756\\n   macro avg       0.65      0.64      0.65       756\\nweighted avg       0.66      0.65      0.65       756\\n', 'test_runtime': 3.6534, 'test_samples_per_second': 30.382, 'test_steps_per_second': 3.832})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-914b451a8399>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metrics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "preds['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabi",
   "language": "python",
   "name": "tabi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
