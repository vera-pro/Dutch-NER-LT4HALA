{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(cur_entry, tokens):\n",
    "    ans = 0\n",
    "    for i, tok in enumerate(tokens[:cur_entry['index']-1]):  # -1 because we start with [CLS]\n",
    "        ans += len(tok.replace('#',''))  \n",
    "        if i:\n",
    "            ans += int(tok[0].isalpha())  # whitespace before every word (not subword or punctuation) except the first\n",
    "        \n",
    "    ans += cur_entry['word'][0].isalpha() # whitespace before our token (unless it's a subword)\n",
    "    return ans\n",
    "\n",
    "# Contains a dirty hack but oh well\n",
    "def post_process(item):\n",
    "    if item['word'].startswith('#'):\n",
    "        item['entity'] = 'I' + item['entity'][1:]\n",
    "    return item\n",
    "\n",
    "def insert_index(item, tokens):\n",
    "    item['start'] = get_index(item, tokens)  \n",
    "    item['end'] = item['start']+len(item['word'].replace('#',''))\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "def visualise(text, preds, path_to_output=None):\n",
    "    ## Step 1: adding entities\n",
    "    entities = []\n",
    "    nlp = spacy.blank(\"nl\")  # it should work with any language\n",
    "    doc = nlp(text+' ') # a hack\n",
    "    \n",
    "    \n",
    "    ner_map = {} \n",
    "    cur_type = ''\n",
    "    cur_start, cur_end = 0, 0\n",
    "\n",
    "    for pred in preds: \n",
    "        ent = pred['entity']\n",
    "        if ent.startswith('B'): # or pred['start'] > cur_end+1: ## a dirty hack in case it failed to predict 'B'\n",
    "            ## Adding the previous entity if it's not empty\n",
    "            if cur_type != '':\n",
    "                char_span = doc.char_span(cur_start, cur_end, cur_type)\n",
    "                if char_span:\n",
    "                    entities.append(char_span)\n",
    "\n",
    "            ## Processing the new entity\n",
    "            cur_type = ent[2:]\n",
    "            if cur_type not in ner_map: \n",
    "                ner_map[cur_type] = len(ner_map)+1\n",
    "            cur_start = pred['start']\n",
    "            cur_end = pred['end']\n",
    "        else: ## there's only 'B' and 'I', 'O' is not included\n",
    "            cur_end = pred['end']\n",
    "\n",
    "    ## Adding the last one\n",
    "    if cur_type != '':\n",
    "        char_span = doc.char_span(cur_start, cur_end, cur_type)\n",
    "        if char_span:\n",
    "            entities.append(char_span)\n",
    "            \n",
    "    doc.ents = entities\n",
    "    \n",
    "    ## Step 2: visualising \n",
    "    colours = sns.color_palette(\"Set2\", len(ner_map)).as_hex()\n",
    "    options = {\"ents\": list(ner_map.keys()),\n",
    "               \"colors\": {ent: colours[ner_map[ent]-1] for ent in ner_map.keys()}\n",
    "              }\n",
    "    if not path_to_output:\n",
    "        displacy_html = displacy.render(doc, style=\"ent\", options=options,jupyter=True)\n",
    "    else:\n",
    "        svg = displacy.render(doc, style='ent',\n",
    "                              options=options, \n",
    "                              jupyter=False)\n",
    "        output_path = Path(path_to_output)\n",
    "        output_path.open('w', encoding='utf-8').write(svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/ivi/ilps/personal/vprovat/KB/models/BERTje-NER-v2\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"/ivi/ilps/personal/vprovat/KB/models/BERTje-NER-v2\")\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "example = \"Ik ben Bert de Jong, en ik woon in Zandvoort aan Zee.\"\n",
    "\n",
    "ner_results = nlp(example)\n",
    "res = [post_process(item) for item in ner_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [tokenizer.decode(tok) for tok in tokenizer(example).input_ids][1:-1]\n",
    "res_for_visualisation = [insert_index(item,tokens) for item in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Ik ben \n",
       "<mark class=\"entity\" style=\"background: #66c2a5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bert de Jong\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", en ik woon in \n",
       "<mark class=\"entity\" style=\"background: #fc8d62; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Zandvoort aan Zee\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ". </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualise(example, res_for_visualisation)#, path_to_output='plots/NER_example.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-PER',\n",
       "  'score': 0.9783231,\n",
       "  'index': 3,\n",
       "  'word': 'Bert',\n",
       "  'start': 7,\n",
       "  'end': 11},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.91749096,\n",
       "  'index': 4,\n",
       "  'word': 'de',\n",
       "  'start': 12,\n",
       "  'end': 14},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.97511953,\n",
       "  'index': 5,\n",
       "  'word': 'Jong',\n",
       "  'start': 15,\n",
       "  'end': 19},\n",
       " {'entity': 'B-LOC',\n",
       "  'score': 0.98678595,\n",
       "  'index': 11,\n",
       "  'word': 'Zandvoort',\n",
       "  'start': 35,\n",
       "  'end': 44},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.6270297,\n",
       "  'index': 12,\n",
       "  'word': 'aan',\n",
       "  'start': 45,\n",
       "  'end': 48},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.8423254,\n",
       "  'index': 13,\n",
       "  'word': 'Ze',\n",
       "  'start': 49,\n",
       "  'end': 51},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.8233484,\n",
       "  'index': 14,\n",
       "  'word': '##e',\n",
       "  'start': 51,\n",
       "  'end': 52}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_for_visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ik ben Jip de Kip, en ik woon in Zandvoort aan Zee'"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ik\n",
      "Current start:  2\n",
      "ben\n",
      "Current start:  6\n",
      "Ik\n",
      "Current start:  2\n",
      "ben\n",
      "Current start:  6\n",
      "Ji\n",
      "Current start:  9\n",
      "Ik\n",
      "Current start:  2\n",
      "ben\n",
      "Current start:  6\n",
      "Ji\n",
      "Current start:  9\n",
      "##p\n",
      "Current start:  10\n",
      "Ik\n",
      "Current start:  2\n",
      "ben\n",
      "Current start:  6\n",
      "Ji\n",
      "Current start:  9\n",
      "##p\n",
      "Current start:  10\n",
      "de\n",
      "Current start:  13\n",
      "Ik\n",
      "Current start:  2\n",
      "ben\n",
      "Current start:  6\n",
      "Ji\n",
      "Current start:  9\n",
      "##p\n",
      "Current start:  10\n",
      "de\n",
      "Current start:  13\n",
      "Kip\n",
      "Current start:  17\n",
      ",\n",
      "Current start:  18\n",
      "en\n",
      "Current start:  21\n",
      "ik\n",
      "Current start:  24\n",
      "woon\n",
      "Current start:  29\n",
      "in\n",
      "Current start:  32\n",
      "Ik\n",
      "Current start:  2\n",
      "ben\n",
      "Current start:  6\n",
      "Ji\n",
      "Current start:  9\n",
      "##p\n",
      "Current start:  10\n",
      "de\n",
      "Current start:  13\n",
      "Kip\n",
      "Current start:  17\n",
      ",\n",
      "Current start:  18\n",
      "en\n",
      "Current start:  21\n",
      "ik\n",
      "Current start:  24\n",
      "woon\n",
      "Current start:  29\n",
      "in\n",
      "Current start:  32\n",
      "Zandvoort\n",
      "Current start:  42\n",
      "Ik\n",
      "Current start:  2\n",
      "ben\n",
      "Current start:  6\n",
      "Ji\n",
      "Current start:  9\n",
      "##p\n",
      "Current start:  10\n",
      "de\n",
      "Current start:  13\n",
      "Kip\n",
      "Current start:  17\n",
      ",\n",
      "Current start:  18\n",
      "en\n",
      "Current start:  21\n",
      "ik\n",
      "Current start:  24\n",
      "woon\n",
      "Current start:  29\n",
      "in\n",
      "Current start:  32\n",
      "Zandvoort\n",
      "Current start:  42\n",
      "aan\n",
      "Current start:  46\n",
      "Ik\n",
      "Current start:  2\n",
      "ben\n",
      "Current start:  6\n",
      "Ji\n",
      "Current start:  9\n",
      "##p\n",
      "Current start:  10\n",
      "de\n",
      "Current start:  13\n",
      "Kip\n",
      "Current start:  17\n",
      ",\n",
      "Current start:  18\n",
      "en\n",
      "Current start:  21\n",
      "ik\n",
      "Current start:  24\n",
      "woon\n",
      "Current start:  29\n",
      "in\n",
      "Current start:  32\n",
      "Zandvoort\n",
      "Current start:  42\n",
      "aan\n",
      "Current start:  46\n",
      "Ze\n",
      "Current start:  49\n"
     ]
    }
   ],
   "source": [
    "for item in res_for_visualisation:\n",
    "    if example[get_index(item,tokens)] != item['word'].replace('#','')[0]:\n",
    "        print(get_index(item,tokens), example[get_index(item,tokens)], '!=', item['word'].replace('#','')[0])\n",
    "#     if example[item['start']:item['end']-1] != item['word'].replace('#',''):\n",
    "#         print(example[item['start']:item['end']-1],'!=', item['word'].replace('#',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'I'.isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ik',\n",
       " 'ben',\n",
       " 'Ji',\n",
       " '##p',\n",
       " 'de',\n",
       " 'Kip',\n",
       " ',',\n",
       " 'en',\n",
       " 'ik',\n",
       " 'woon',\n",
       " 'in',\n",
       " 'Zandvoort',\n",
       " 'aan',\n",
       " 'Ze',\n",
       " '##e']"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabi",
   "language": "python",
   "name": "tabi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
