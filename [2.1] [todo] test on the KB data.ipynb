{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_NHA.txt', 'test_RHC.txt', 'test_SA.txt', 'test_VOC.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests = 'test_NHA.txt  test_RHC.txt  test_SA.txt  test_VOC.txt'.split()\n",
    "tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3b643d26fd4a5f8929a19d27ec1bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "905cdbfaf77e4abbb93f44e068952668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c168971245d4a278501ae29d82ff415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482fd9cfed214c0ab839e563cee32159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a04009366ef4bba8bab4abcef7b330a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740557dc95d34a709c4832686a726ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments, AutoModel\n",
    "from datasets import load_dataset, load_metric, Dataset, DatasetDict\n",
    "import numpy as np\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "from data_utils import prepare_data, convert_to_dataset\n",
    "\n",
    "# train and val are redundant but we need the labels, sooo\n",
    "train = prepare_data('/ivi/ilps/personal/vprovat/KB/data/AITrainingset/Data/train.txt')\n",
    "val = prepare_data('/ivi/ilps/personal/vprovat/KB/data/AITrainingset/Data/validation.txt')\n",
    "\n",
    "tests_prepared = [\n",
    "     prepare_data('/ivi/ilps/personal/vprovat/KB/data/AITrainingset/Data/'+test) for test in tests\n",
    "]\n",
    "\n",
    "label_list = sorted(list(set([token_data[1] for sentence in train for token_data in sentence if token_data])))\n",
    "label_map = {label: i for i, label in enumerate(label_list)}\n",
    "id2label_original = {i: label for i, label in enumerate(label_list)}\n",
    "label2id = {label: i for i, label in enumerate(label_list)}\n",
    "\n",
    "train_data = convert_to_dataset(train, label_map)\n",
    "val_data = convert_to_dataset(val, label_map)\n",
    "test_data = [convert_to_dataset(test, label_map)\n",
    "             for test in tests_prepared]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = {\n",
    "    \"train\": train_data,\n",
    "    \"validation\": val_data}\n",
    "for i, test in enumerate(tests):\n",
    "    dct[test.split('.')[0]] = test_data[i]\n",
    "\n",
    "datasets = DatasetDict(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wrong_predictions(eval_prediction): # experimental, will be improved\n",
    "    predictions, labels = eval_prediction\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    \n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id2label_original[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    res = []\n",
    "    for i in range(len(true_predictions)):\n",
    "        if true_predictions[i] != true_labels[i]:\n",
    "            res.append((i, true_predictions[i],true_labels[i]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_prediction):\n",
    "    predictions, labels = eval_prediction\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "#     print(predictions) # todo remove\n",
    "\n",
    "    # for evaluating wikineural, which has a different number of labels:\n",
    "    # set the extra labels to 'O' and hope for the best\n",
    "#     filtered_predictions = [\n",
    "#         [p if p < len(label_list) else label2id['O'] for p in prediction]\n",
    "#         for prediction in predictions\n",
    "#     ]\n",
    "    \n",
    "#     predictions = filtered_predictions\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id2label_original[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    # todo: remove debug output\n",
    "#     print(true_predictions[0])\n",
    "#     print(true_labels[0])\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision_score(true_labels, true_predictions),\n",
    "        \"recall\": recall_score(true_labels, true_predictions),\n",
    "        \"f1\": f1_score(true_labels, true_predictions),\n",
    "        \"classification_report\": classification_report(true_labels, true_predictions),\n",
    "    }\n",
    "\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True, padding=True, return_tensors='pt'\n",
    "    )\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "def data_collator(data):\n",
    "    input_ids = [torch.tensor(item[\"input_ids\"]) for item in data]\n",
    "    attention_mask = [torch.tensor(item[\"attention_mask\"]) for item in data]\n",
    "    labels = [torch.tensor(item[\"labels\"]) for item in data]\n",
    "\n",
    "    input_ids = torch.nn.utils.rnn.pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    attention_mask = torch.nn.utils.rnn.pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=-100)\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = {'GysBERT': \"/ivi/ilps/personal/vprovat/KB/models/GysBERT-NER-v2\",\n",
    "              'BERTje': \"/ivi/ilps/personal/vprovat/KB/models/BERTje-NER-v2\",\n",
    "              'BERT-multi-cased': \"/ivi/ilps/personal/vprovat/KB/models/BERT-multi-cased-NER-v2\",\n",
    "              'WikiNEuRal': \"Babelscape/wikineural-multilingual-ner\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_trainer(model_name):\n",
    "# if True:\n",
    "#     model_name = model_names['BERTje']\n",
    "    global tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "    global model\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "    tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True)\n",
    "    \n",
    "    global id2label\n",
    "    id2label = model.config.id2label\n",
    "    global label2id\n",
    "    label2id = model.config.label2id\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "    res = {}\n",
    "    for test in tests:\n",
    "        dataset_name = test.split('.')[0]\n",
    "        preds = trainer.predict(tokenized_datasets[dataset_name])\n",
    "        res[test] = preds.metrics\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11104 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2761 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/114 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/111 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " ...\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 5 2 6]\n",
      " [6 6 6 ... 6 6 6]]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 6 6 ... 6 6 6]\n",
      " [6 6 1 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 1 4 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " ...\n",
      " [6 6 2 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 0 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " ...\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 1 4 ... 6 6 6]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_NHA.txt': {'test_loss': 0.11342580616474152,\n",
       "  'test_precision': 0.709470304975923,\n",
       "  'test_recall': 0.6567607726597325,\n",
       "  'test_f1': 0.6820987654320987,\n",
       "  'test_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.80      0.74      0.77       236\\n         PER       0.77      0.72      0.74       336\\n        TIME       0.29      0.26      0.27       101\\n\\n   micro avg       0.71      0.66      0.68       673\\n   macro avg       0.62      0.57      0.59       673\\nweighted avg       0.71      0.66      0.68       673\\n',\n",
       "  'test_runtime': 1.7023,\n",
       "  'test_samples_per_second': 29.959,\n",
       "  'test_steps_per_second': 4.112},\n",
       " 'test_RHC.txt': {'test_loss': 0.3024003505706787,\n",
       "  'test_precision': 0.8095238095238095,\n",
       "  'test_recall': 0.7555555555555555,\n",
       "  'test_f1': 0.7816091954022989,\n",
       "  'test_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       1.00      0.82      0.90        17\\n         PER       0.71      0.71      0.71        24\\n        TIME       0.75      0.75      0.75         4\\n\\n   micro avg       0.81      0.76      0.78        45\\n   macro avg       0.82      0.76      0.79        45\\nweighted avg       0.82      0.76      0.79        45\\n',\n",
       "  'test_runtime': 0.1128,\n",
       "  'test_samples_per_second': 26.586,\n",
       "  'test_steps_per_second': 8.862},\n",
       " 'test_SA.txt': {'test_loss': 0.09569220244884491,\n",
       "  'test_precision': 0.7996545768566494,\n",
       "  'test_recall': 0.759016393442623,\n",
       "  'test_f1': 0.7788057190916737,\n",
       "  'test_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.81      0.78      0.80       245\\n         PER       0.80      0.74      0.77       722\\n        TIME       0.80      0.78      0.79       253\\n\\n   micro avg       0.80      0.76      0.78      1220\\n   macro avg       0.80      0.77      0.78      1220\\nweighted avg       0.80      0.76      0.78      1220\\n',\n",
       "  'test_runtime': 3.6777,\n",
       "  'test_samples_per_second': 30.998,\n",
       "  'test_steps_per_second': 4.079},\n",
       " 'test_VOC.txt': {'test_loss': 0.09862799942493439,\n",
       "  'test_precision': 0.657258064516129,\n",
       "  'test_recall': 0.6468253968253969,\n",
       "  'test_f1': 0.652,\n",
       "  'test_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.78      0.76      0.77       307\\n         PER       0.53      0.51      0.52       272\\n        TIME       0.64      0.66      0.65       177\\n\\n   micro avg       0.66      0.65      0.65       756\\n   macro avg       0.65      0.64      0.65       756\\nweighted avg       0.66      0.65      0.65       756\\n',\n",
       "  'test_runtime': 3.6228,\n",
       "  'test_samples_per_second': 30.639,\n",
       "  'test_steps_per_second': 3.864}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_with_trainer(model_names['BERT-multi-cased'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11104 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2761 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/111 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 5 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 2 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vprovat/anaconda3/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vprovat/anaconda3/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 11.0033540725708,\n",
       " 'test_precision': 0.2912371134020619,\n",
       " 'test_recall': 0.29161290322580646,\n",
       " 'test_f1': 0.29142488716956805,\n",
       " 'test_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.48      0.47      0.48       312\\n        MISC       0.00      0.00      0.00         0\\n         ORG       0.00      0.00      0.00         0\\n         PER       0.35      0.28      0.31       283\\n        TIME       0.00      0.00      0.00       180\\n\\n   micro avg       0.29      0.29      0.29       775\\n   macro avg       0.17      0.15      0.16       775\\nweighted avg       0.32      0.29      0.30       775\\n',\n",
       " 'test_runtime': 3.7133,\n",
       " 'test_samples_per_second': 29.892,\n",
       " 'test_steps_per_second': 3.77}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_with_trainer(model_names['WikiNEuRal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GysBERT /ivi/ilps/personal/vprovat/KB/models/GysBERT-NER-v2\n",
      "BERTje /ivi/ilps/personal/vprovat/KB/models/BERTje-NER-v2\n",
      "BERT-multi-cased /ivi/ilps/personal/vprovat/KB/models/BERT-multi-cased-NER-v2\n",
      "WikiNEuRal Babelscape/wikineural-multilingual-ner\n"
     ]
    }
   ],
   "source": [
    "for name, path in model_names.items():\n",
    "    print(name, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = '              precision    recall  f1-score   support\\n\\n         LOC       0.48      0.47      0.48       312\\n        MISC       0.00      0.00      0.00         0\\n         ORG       0.00      0.00      0.00         0\\n         PER       0.35      0.28      0.31       283\\n        TIME       0.00      0.00      0.00       180\\n\\n   micro avg       0.29      0.29      0.29       775\\n   macro avg       0.17      0.15      0.16       775\\nweighted avg       0.32      0.29      0.30       775\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' LOC', ' 0.48', '0.47', '0.48', ' 312']\n",
      "['MISC', ' 0.00', '0.00', '0.00', ' 0']\n",
      "[' ORG', ' 0.00', '0.00', '0.00', ' 0']\n",
      "[' PER', ' 0.35', '0.28', '0.31', ' 283']\n",
      "['TIME', ' 0.00', '0.00', '0.00', ' 180']\n",
      "[' micro avg', ' 0.29', '0.29', '0.29', ' 775']\n",
      "[' macro avg', ' 0.17', '0.15', '0.16', ' 775']\n",
      "['weighted avg', ' 0.32', '0.29', '0.30', ' 775']\n"
     ]
    }
   ],
   "source": [
    "for line in test.split('\\n')[1:]:\n",
    "#     if len(line.split()) < 2:\n",
    "#         continue\n",
    "#     print(line)\n",
    "#     print(line.split('  '))\n",
    "    row = [item for item in line.split('  ') if item]\n",
    "    if not row:\n",
    "        continue\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([Dataset({\n",
       "    features: ['tokens', 'ner_tags'],\n",
       "    num_rows: 11104\n",
       "}), Dataset({\n",
       "    features: ['tokens', 'ner_tags'],\n",
       "    num_rows: 2761\n",
       "}), Dataset({\n",
       "    features: ['tokens', 'ner_tags'],\n",
       "    num_rows: 51\n",
       "}), Dataset({\n",
       "    features: ['tokens', 'ner_tags'],\n",
       "    num_rows: 3\n",
       "}), Dataset({\n",
       "    features: ['tokens', 'ner_tags'],\n",
       "    num_rows: 114\n",
       "}), Dataset({\n",
       "    features: ['tokens', 'ner_tags'],\n",
       "    num_rows: 111\n",
       "})])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11104 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2761 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/114 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/111 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " ...\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      "  6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 4 6 6 6 6 6 6 6 6 6 6 6\n",
      "  6 6 2 5 5 5 5 6 6 6 6 6 6 6 2 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 1 4\n",
      "  4 4 6 6 2 5 5 5 5 5 5 6 0 0 0 6 6 6 1 4 4 4 1 6 6 6 6 6 6 6 1 4 4 1 6 6\n",
      "  0 0 0 0 6 0 4 4 1 4 4 4 6 6 0 3 0 0 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      "  6 6 6 6 6 1 4 4 4 6 6 6 6 6 6 1 4 1 4 4 6 4 6 6 6 6 6 6 1 4 6 4 6 6 4 6\n",
      "  6 6 6 6 6 6 6 6 4 6 6 6 1 4 4 6 6 1 1 4 4 4 4 6 6 6 6 1 4 0 6 6 6 6 6 6\n",
      "  0 0 4 6 6 6 6 6 6 4 6 6 6 1 4 6 4 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      "  6 6 6 6 4 0 6 6 2 5 5 5 5 5 5 5 6 4]\n",
      " [6 6 1 4 4 4 4 1 4 6 6 6 6 6 6 6 0 3 6 6 0 0 6 6 0 6 6 6 6 0 6 6 6 6 6 6\n",
      "  6 6 6 6 6 6 6 6 6 6 0 6 6 6 6 6 6 6 6 6 2 2 5 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      "  6 6 6 6 6 1 4 4 4 1 6 6 6 6 0 0 6 6 6 6 6 6 6 6 6 1 4 4 1 6 6 6 6 6 6 6\n",
      "  6 6 6 6 6 6 6 6 6 0 0 6 6 0 0 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      "  6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 1 4 4 6 6 6 6 6 6 1\n",
      "  4 4 6 6 6 0 3 6 6 6 6 1 4 4 6 1 4 1 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      "  6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      "  6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      "  6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      " [6 6 6 6 6 6 1 4 4 4 4 4 1 6 6 6 6 6 6 6 6 6 1 4 4 4 6 6 0 6 6 6 6 6 6 6\n",
      "  6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 4 6\n",
      "  6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      "  6 6 6 4 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      "  6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      "  6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      "  6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      "  6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      "  6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 1 4 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " ...\n",
      " [6 6 2 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 0 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " ...\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 1 4 ... 6 6 6]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11104 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2761 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/114 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/111 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 4 6]\n",
      " ...\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 6 6 ... 5 5 6]\n",
      " [6 6 1 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 1 4 ... 6 6 6]\n",
      " [6 6 6 ... 4 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " ...\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 4 6 6]]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 0 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " ...\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 1 4 ... 6 6 6]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11104 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2761 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/114 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/111 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " ...\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 5 2 6]\n",
      " [6 6 6 ... 6 6 6]]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 6 6 ... 6 6 6]\n",
      " [6 6 1 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 1 4 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " ...\n",
      " [6 6 2 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 0 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " ...\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 1 4 ... 6 6 6]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11104 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2761 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/114 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/111 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 6]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 5 ... 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 5 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 2 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io   \n",
    "\n",
    "dfs = []\n",
    "for name, path in model_names.items():\n",
    "    res = evaluate_with_trainer(path)\n",
    "    column_names = ['model_name','dataset', 'label','precision','recall','f1-score','support']\n",
    "    df = pd.DataFrame(columns=column_names, dtype=object)\n",
    "    for test in tests: \n",
    "        for line in res[test]['test_classification_report'].split('\\n')[1:]: # the first one is '\\n\\n'\n",
    "            row = [item for item in line.split('  ') if item]\n",
    "            if not row:\n",
    "                continue\n",
    "            df.loc[len(df)] = [name, test]+row\n",
    "#     df = pd.read_csv(io.StringIO(res['test_classification_report']), sep=\"\\t\")\n",
    "#     df['model_name'] = name\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>dataset</th>\n",
       "      <th>label</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GysBERT</td>\n",
       "      <td>test_NHA.txt</td>\n",
       "      <td>LOC</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.78</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GysBERT</td>\n",
       "      <td>test_NHA.txt</td>\n",
       "      <td>PER</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.76</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GysBERT</td>\n",
       "      <td>test_NHA.txt</td>\n",
       "      <td>TIME</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.29</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GysBERT</td>\n",
       "      <td>test_NHA.txt</td>\n",
       "      <td>micro avg</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GysBERT</td>\n",
       "      <td>test_NHA.txt</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.61</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>WikiNEuRal</td>\n",
       "      <td>test_VOC.txt</td>\n",
       "      <td>PER</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.31</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>WikiNEuRal</td>\n",
       "      <td>test_VOC.txt</td>\n",
       "      <td>TIME</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>WikiNEuRal</td>\n",
       "      <td>test_VOC.txt</td>\n",
       "      <td>micro avg</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>WikiNEuRal</td>\n",
       "      <td>test_VOC.txt</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.16</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>WikiNEuRal</td>\n",
       "      <td>test_VOC.txt</td>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name       dataset         label precision recall f1-score support\n",
       "0      GysBERT  test_NHA.txt           LOC      0.80   0.77     0.78     252\n",
       "1      GysBERT  test_NHA.txt           PER      0.78   0.74     0.76     355\n",
       "2      GysBERT  test_NHA.txt          TIME      0.32   0.27     0.29     109\n",
       "3      GysBERT  test_NHA.txt     micro avg      0.73   0.68     0.70     716\n",
       "4      GysBERT  test_NHA.txt     macro avg      0.63   0.59     0.61     716\n",
       "..         ...           ...           ...       ...    ...      ...     ...\n",
       "26  WikiNEuRal  test_VOC.txt           PER      0.35   0.28     0.31     283\n",
       "27  WikiNEuRal  test_VOC.txt          TIME      0.00   0.00     0.00     180\n",
       "28  WikiNEuRal  test_VOC.txt     micro avg      0.29   0.29     0.29     775\n",
       "29  WikiNEuRal  test_VOC.txt     macro avg      0.17   0.15     0.16     775\n",
       "30  WikiNEuRal  test_VOC.txt  weighted avg      0.32   0.29     0.30     775\n",
       "\n",
       "[103 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.concat(dfs)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv('NER_eval_results_alles.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11104 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2761 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/111 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 0 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " ...\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 1 4 ... 6 6 6]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.07860732823610306,\n",
       " 'test_precision': 0.695364238410596,\n",
       " 'test_recall': 0.6844850065189049,\n",
       " 'test_f1': 0.6898817345597898,\n",
       " 'test_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.78      0.78      0.78       309\\n         PER       0.62      0.59      0.60       278\\n        TIME       0.66      0.67      0.66       180\\n\\n   micro avg       0.70      0.68      0.69       767\\n   macro avg       0.69      0.68      0.68       767\\nweighted avg       0.69      0.68      0.69       767\\n',\n",
       " 'test_runtime': 3.7048,\n",
       " 'test_samples_per_second': 29.961,\n",
       " 'test_steps_per_second': 3.779}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_with_trainer(model_names['BERTje'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11104 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2761 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/111 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 0 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " ...\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 1 4 ... 6 6 6]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.11065434664487839,\n",
       " 'test_precision': 0.6722797927461139,\n",
       " 'test_recall': 0.6688144329896907,\n",
       " 'test_f1': 0.6705426356589146,\n",
       " 'test_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.75      0.78      0.76       313\\n         PER       0.57      0.53      0.55       283\\n        TIME       0.69      0.69      0.69       180\\n\\n   micro avg       0.67      0.67      0.67       776\\n   macro avg       0.67      0.67      0.67       776\\nweighted avg       0.67      0.67      0.67       776\\n',\n",
       " 'test_runtime': 3.7261,\n",
       " 'test_samples_per_second': 29.79,\n",
       " 'test_steps_per_second': 3.757}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_with_trainer(model_names['GysBERT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[[-0.8846255 , -0.20053461, -2.723233  , ..., -1.5204369 ,\n",
       "         -3.548008  ,  9.511862  ],\n",
       "        [ 5.6675086 , -0.5285765 , -2.26615   , ..., -1.6218034 ,\n",
       "         -2.404584  ,  0.69367194],\n",
       "        [-0.5783778 , -2.9816043 , -2.8909168 , ..., -1.5484601 ,\n",
       "         -1.4718972 ,  6.1818666 ],\n",
       "        ...,\n",
       "        [ 2.3493235 , -1.2068609 , -3.5420794 , ..., -1.4829181 ,\n",
       "         -3.1683383 ,  4.7888618 ],\n",
       "        [-0.72117543, -0.9307784 , -2.2060997 , ..., -1.0914435 ,\n",
       "         -3.1423402 ,  9.487557  ],\n",
       "        [-1.569152  , -1.2889202 , -2.636608  , ...,  0.15824848,\n",
       "         -2.236063  ,  7.421688  ]],\n",
       "\n",
       "       [[-1.5841635 , -0.7333175 , -2.3293574 , ..., -1.359286  ,\n",
       "         -2.8213515 ,  9.910175  ],\n",
       "        [-2.312314  , -1.5694518 , -1.9815735 , ..., -0.73888   ,\n",
       "         -1.6240867 ,  9.370352  ],\n",
       "        [-2.071714  , -0.81145626, -2.708225  , ..., -0.68706286,\n",
       "         -1.5662781 ,  8.74781   ],\n",
       "        ...,\n",
       "        [-1.3483778 , -0.6541185 , -2.1392243 , ..., -0.8131753 ,\n",
       "         -3.051442  ,  8.826292  ],\n",
       "        [-1.4079125 , -0.92248905, -1.7853128 , ..., -1.0237157 ,\n",
       "         -3.0599935 ,  9.9496765 ],\n",
       "        [-2.025554  , -1.4181095 , -2.0482807 , ...,  0.4915901 ,\n",
       "         -1.7311492 ,  6.933034  ]],\n",
       "\n",
       "       [[-1.5410277 , -1.5287145 , -1.897834  , ..., -1.6536614 ,\n",
       "         -2.3666902 ,  9.490026  ],\n",
       "        [-1.9361404 , -1.948404  , -0.15296419, ..., -0.8077831 ,\n",
       "         -1.9740096 ,  9.001076  ],\n",
       "        [-2.531062  , -2.3002832 , -2.623624  , ..., -0.03863568,\n",
       "         -1.3896129 ,  9.653441  ],\n",
       "        ...,\n",
       "        [-1.7256321 , -1.5605744 , -2.8174422 , ..., -1.0134491 ,\n",
       "         -2.819878  ,  9.722782  ],\n",
       "        [-1.4355643 , -1.5171486 , -2.3357818 , ..., -1.5788561 ,\n",
       "         -2.620981  , 10.292501  ],\n",
       "        [-1.9380301 , -1.8309193 , -1.7772994 , ..., -0.26113698,\n",
       "         -1.3680869 ,  7.5538187 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.423385  , -0.35207585, -1.9881976 , ..., -0.9381608 ,\n",
       "         -2.1933975 ,  7.3699083 ],\n",
       "        [-2.297593  , -1.2020236 , -2.1021087 , ..., -1.0209163 ,\n",
       "         -1.4958185 ,  9.153282  ],\n",
       "        [-2.0511613 , -0.93708646, -2.069503  , ..., -1.4545549 ,\n",
       "         -2.5420444 ,  9.383308  ],\n",
       "        ...,\n",
       "        [ 0.04308483, -0.99532914, -1.8578511 , ..., -0.44440377,\n",
       "         -1.7085315 ,  4.19421   ],\n",
       "        [-0.9014315 ,  0.04227867, -2.269631  , ..., -1.1031961 ,\n",
       "         -3.632776  ,  8.799566  ],\n",
       "        [-1.9775962 , -0.9058244 , -2.5907772 , ...,  0.5330943 ,\n",
       "         -2.3180165 ,  7.286789  ]],\n",
       "\n",
       "       [[-1.3886119 ,  0.0225039 , -2.5974257 , ..., -0.36339632,\n",
       "         -3.3690014 ,  8.147543  ],\n",
       "        [-2.1088703 , -2.4328554 , -1.5159694 , ..., -1.0118967 ,\n",
       "         -1.9269505 , 10.111185  ],\n",
       "        [-1.6493293 , -2.5843956 , -0.7399124 , ..., -1.2074455 ,\n",
       "         -2.1959562 ,  9.696609  ],\n",
       "        ...,\n",
       "        [-1.0954031 ,  1.1607004 , -2.3033178 , ...,  0.5037799 ,\n",
       "         -4.051877  ,  7.3043566 ],\n",
       "        [-0.9942391 , -0.01312329, -1.6278763 , ..., -0.65985954,\n",
       "         -4.0253854 ,  9.226078  ],\n",
       "        [-2.2898602 , -0.82310325, -2.8220177 , ...,  0.9339499 ,\n",
       "         -2.3488276 ,  7.2428393 ]],\n",
       "\n",
       "       [[-1.7883204 ,  1.6297017 , -3.2071881 , ...,  0.45594564,\n",
       "         -3.2162738 ,  6.2929983 ],\n",
       "        [-0.39101598,  5.7095046 , -1.6804403 , ...,  1.3893739 ,\n",
       "         -2.8189762 , -0.46831727],\n",
       "        [-2.2936814 ,  1.8047737 , -2.8936427 , ...,  5.9130874 ,\n",
       "         -2.0843034 ,  0.14492857],\n",
       "        ...,\n",
       "        [ 2.6313264 , -0.3746079 , -2.0245633 , ..., -1.5295966 ,\n",
       "         -3.7279708 ,  5.113908  ],\n",
       "        [-1.0308533 , -0.15208574, -2.2868803 , ..., -0.80736613,\n",
       "         -3.4749806 ,  9.501987  ],\n",
       "        [-2.0567803 , -1.1979206 , -2.4819014 , ...,  0.4026598 ,\n",
       "         -1.9791249 ,  7.275797  ]]], dtype=float32), label_ids=array([[-100,    0,    6, ..., -100, -100, -100],\n",
       "       [-100,    6,    6, ..., -100, -100, -100],\n",
       "       [-100,    6,    6, ..., -100, -100, -100],\n",
       "       ...,\n",
       "       [-100,    6, -100, ..., -100, -100, -100],\n",
       "       [-100,    6,    6, ..., -100, -100, -100],\n",
       "       [-100,    1,    4, ..., -100, -100, -100]]), metrics={'test_loss': 0.07860732823610306, 'test_precision': 0.695364238410596, 'test_recall': 0.6844850065189049, 'test_f1': 0.6898817345597898, 'test_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.78      0.78      0.78       309\\n         PER       0.62      0.59      0.60       278\\n        TIME       0.66      0.67      0.66       180\\n\\n   micro avg       0.70      0.68      0.69       767\\n   macro avg       0.69      0.68      0.68       767\\nweighted avg       0.69      0.68      0.69       767\\n', 'test_runtime': 3.7311, 'test_samples_per_second': 29.75, 'test_steps_per_second': 3.752})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model_name=\"/ivi/ilps/personal/vprovat/KB/models/BERT-multi-cased-NER-v2\"):\n",
    "    global tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "    tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True)\n",
    "    global id2label\n",
    "    id2label = model.config.id2label\n",
    "    global label2id\n",
    "    label2id = model.config.label2id\n",
    "    \n",
    "    toks = data_collator(tokenized_datasets['test'])\n",
    "    preds = model(toks['input_ids'])\n",
    "    \n",
    "#     print(preds.logits[0]) # todo remove\n",
    "\n",
    "    return compute_metrics((preds.logits.detach().numpy(), tokenized_datasets['test']['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11104 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2761 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/111 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name=model_names[\"WikiNEuRal\"]\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True)\n",
    "id2label = model.config.id2label\n",
    "label2id = model.config.label2id\n",
    "    \n",
    "toks = data_collator(tokenized_datasets['test'])\n",
    "preds = model(toks['input_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.logits[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics((preds.logits.detach().numpy(), tokenized_datasets['test']['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2,  1945,  1508,  4626,    16, 24360,  1508,  1658, 21885,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Amsterdam is mooi, Timor is nog mooier\"\n",
    "toks_new = tokenizer(text,return_tensors='pt')\n",
    "toks_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2, 24360,  1456,  ...,     0,     0,     0],\n",
       "         [    2,  2763,    18,  ...,     0,     0,     0],\n",
       "         [    2, 13600,  2942,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [    2,  7213,  9280,  ...,     0,     0,     0],\n",
       "         [    2,  1486,  2821,  ...,     0,     0,     0],\n",
       "         [    2,  8635,  5744,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'labels': tensor([[-100,    0,    6,  ..., -100, -100, -100],\n",
       "         [-100,    6,    6,  ..., -100, -100, -100],\n",
       "         [-100,    6,    6,  ..., -100, -100, -100],\n",
       "         ...,\n",
       "         [-100,    6, -100,  ..., -100, -100, -100],\n",
       "         [-100,    6,    6,  ..., -100, -100, -100],\n",
       "         [-100,    1,    4,  ..., -100, -100, -100]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collated = data_collator(tokenized_datasets['test'])\n",
    "collated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b776427dac3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1765\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1767\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1768\u001b[0m         )\n\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have to specify either input_ids or inputs_embeds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "model(collated['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenClassifierOutput(loss=None, logits=tensor([[[-0.5427,  0.6064, -0.9945, -2.6852, -2.6771, -1.9216,  7.4962],\n",
       "         [ 7.5385, -2.3297, -1.9815,  2.2804, -3.7618, -3.9279,  1.5158],\n",
       "         [-2.7782, -1.5884, -3.4236, -1.4898, -1.4373, -2.4613, 10.2054],\n",
       "         [ 1.0658, -0.6538, -2.0952, -2.4094, -3.1959, -3.2366,  7.6695],\n",
       "         [-2.5549, -2.0135, -3.2106, -0.1299, -1.0148, -2.7319,  9.3680],\n",
       "         [-2.1994, -0.4250, -2.8736, -1.6528, -1.0364, -3.7920,  9.7953],\n",
       "         [ 8.4146, -1.4474,  1.5184, -1.6112, -3.6887, -1.9291, -0.6003],\n",
       "         [ 7.2142, -2.1879, -0.0754,  2.4800, -3.8119, -1.2636, -1.2760],\n",
       "         [-2.3924, -1.8151, -2.9774, -1.0514, -1.6791, -2.8544, 10.5226],\n",
       "         [ 8.8415, -1.3115, -0.3948, -0.2439, -4.4734, -2.5845, -0.8180],\n",
       "         [ 3.9327, -3.4434, -3.3043,  7.1931, -2.8903, -1.3326, -0.2706],\n",
       "         [-2.7918, -1.4254, -2.2763, -2.7268, -2.1909, -2.0980, 11.1556],\n",
       "         [-2.5494, -1.6920, -2.1994, -3.0338, -2.1286, -2.1863, 11.3971],\n",
       "         [-2.5968, -1.8212, -2.2301, -2.6998, -2.2881, -1.8654, 11.3967],\n",
       "         [-2.1881, -0.8934, -2.1353, -3.2491, -2.2740, -2.2943, 11.2588],\n",
       "         [-2.8291, -1.8785, -2.2995, -2.7487, -2.0088, -1.7234, 11.3012],\n",
       "         [-2.4620, -1.4871, -2.6799, -2.7077, -1.9630, -2.3865, 11.2965],\n",
       "         [-2.1461, -2.1339, -2.0396, -2.3685, -2.3552, -2.3426, 11.1158],\n",
       "         [-2.7719, -1.7736, -1.8607, -2.7474, -1.9088, -1.9158, 11.0606],\n",
       "         [-2.0058, -1.2589, -1.8204, -3.0220, -2.6841, -2.4501, 11.2128],\n",
       "         [ 1.5782,  2.4178, -2.5076, -4.1694, -2.3145, -3.5356,  5.9495],\n",
       "         [ 0.6926,  0.8554, -1.7275, -2.6247,  1.1378, -3.1386,  4.3018],\n",
       "         [-0.7477, -1.2154, -3.5194, -2.1342, -0.9345, -3.5876,  8.7606],\n",
       "         [-2.1238, -1.2718, -2.8520, -2.3264, -1.5912, -3.0387, 10.8796],\n",
       "         [-2.9689, -1.2302, -2.4556, -2.9169, -1.5395, -2.2466, 11.2171],\n",
       "         [ 1.0932, -0.2829, -2.1901, -4.3890, -2.5701, -2.8094,  8.4244],\n",
       "         [ 0.7221, -1.5491, -2.6893, -2.7826, -2.4088, -3.2040,  8.6328],\n",
       "         [-1.1610, -0.9846, -2.2412, -2.6632, -2.1397, -3.1844, 10.1462],\n",
       "         [-1.2142, -0.4467, -3.7376, -2.4438, -0.8449, -3.3179,  9.5989],\n",
       "         [-2.8490, -1.1078, -2.1562, -2.6356, -1.8960, -2.4169, 10.9598],\n",
       "         [-0.1087, -0.5347, -0.5988, -2.7518, -2.7841, -1.4720,  7.1651]]],\n",
       "       grad_fn=<AddBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(toks_new['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Timor',\n",
       " 'en',\n",
       " 'Passant',\n",
       " 'over',\n",
       " 'sirbon',\n",
       " 'en',\n",
       " 'Japara',\n",
       " 'brieven',\n",
       " 'daar',\n",
       " 'mede',\n",
       " 'afgegaan',\n",
       " 'de',\n",
       " 'geschillen',\n",
       " 'tusschen',\n",
       " 'de',\n",
       " 'amarassiers',\n",
       " 'en',\n",
       " 'Coepanse',\n",
       " 'bontgenoten;',\n",
       " 'Continueeren',\n",
       " 'nog',\n",
       " 'naden',\n",
       " 'onden',\n",
       " '133',\n",
       " '8.',\n",
       " 'lasten',\n",
       " 'rijs',\n",
       " '100',\n",
       " '.',\n",
       " 'Jatij',\n",
       " 'en',\n",
       " '20.',\n",
       " 'affuijt',\n",
       " 'planken',\n",
       " 'En',\n",
       " 'bedrage',\n",
       " 'van',\n",
       " 'ï¿½5532:',\n",
       " '14',\n",
       " ':',\n",
       " 'waarom',\n",
       " 'bij',\n",
       " 'ons',\n",
       " 'goetgedagt',\n",
       " 'is,',\n",
       " 'dat',\n",
       " 'bodempje',\n",
       " 'vermits',\n",
       " 'het',\n",
       " 'vroeg',\n",
       " 'genoeg',\n",
       " 'in',\n",
       " 'den',\n",
       " 'tijt',\n",
       " 'was',\n",
       " 'en',\n",
       " 'passant',\n",
       " 'ook',\n",
       " 'sirbon',\n",
       " 'en',\n",
       " 'Japara',\n",
       " 'te',\n",
       " 'laten',\n",
       " 'aangieren,',\n",
       " 'om',\n",
       " 'met',\n",
       " 'eenen',\n",
       " 'een',\n",
       " 'partij',\n",
       " 'Coopmansz',\n",
       " ':',\n",
       " 'en',\n",
       " 'provisien',\n",
       " 'vor',\n",
       " 'die',\n",
       " 'comptoiren',\n",
       " 'over',\n",
       " 'te',\n",
       " 'brengen,',\n",
       " 'met',\n",
       " 'alsulken',\n",
       " 'principaal',\n",
       " 'antwoort',\n",
       " 'schrijven',\n",
       " 'aan',\n",
       " 'den',\n",
       " 'onder',\n",
       " 'coopman',\n",
       " 'Willem',\n",
       " 'moerman',\n",
       " 'en',\n",
       " 'raad,',\n",
       " 'als',\n",
       " 'nevens',\n",
       " 'het',\n",
       " 'vorige',\n",
       " 'praeadvis,',\n",
       " 'in',\n",
       " 'ï¿½t',\n",
       " 'afgaande',\n",
       " 'generaal',\n",
       " 'Judisch',\n",
       " 'brieffboek',\n",
       " 'staat',\n",
       " 'ingeschreven',\n",
       " 'de',\n",
       " 'onderlinge',\n",
       " 'geschillen',\n",
       " 'tussen',\n",
       " 'onse',\n",
       " 'timorse',\n",
       " 'off',\n",
       " 'Coepanse',\n",
       " 'bondgenoten,',\n",
       " 'en',\n",
       " 'die',\n",
       " 'der',\n",
       " 'portugesen',\n",
       " 'off',\n",
       " 'amassiers,',\n",
       " 'hare',\n",
       " 'gebuuren,',\n",
       " 'Continueeren',\n",
       " 'nog',\n",
       " 'aen',\n",
       " 'nader',\n",
       " 'onden,',\n",
       " 'dog',\n",
       " 'siende',\n",
       " 'wij',\n",
       " 'die',\n",
       " 'niet',\n",
       " 'veel',\n",
       " 'meer',\n",
       " 'aan',\n",
       " 'trekken,',\n",
       " 'zijn',\n",
       " 'ook',\n",
       " 'vanselve',\n",
       " 'minder',\n",
       " 'dan',\n",
       " 'voor',\n",
       " 'henen',\n",
       " 'te',\n",
       " 'beduijden;',\n",
       " 'en',\n",
       " 'soo',\n",
       " 'is',\n",
       " 'ï¿½t',\n",
       " 'even',\n",
       " 'sodanig']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['test']['tokens'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-100,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " 6,\n",
       " 0,\n",
       " -100,\n",
       " 6,\n",
       " 0,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " -100,\n",
       " 6,\n",
       " -100,\n",
       " -100,\n",
       " 6,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " 6,\n",
       " -100,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " -100,\n",
       " 6,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " 6,\n",
       " 0,\n",
       " -100,\n",
       " 6,\n",
       " 0,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " 1,\n",
       " 1,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " 6,\n",
       " -100,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " -100,\n",
       " 6,\n",
       " -100,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " 6,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['test']['labels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-100,    0,    6,  ..., -100, -100, -100],\n",
       "        [-100,    6,    6,  ..., -100, -100, -100],\n",
       "        [-100,    6,    6,  ..., -100, -100, -100],\n",
       "        ...,\n",
       "        [-100,    6, -100,  ..., -100, -100, -100],\n",
       "        [-100,    6,    6,  ..., -100, -100, -100],\n",
       "        [-100,    1,    4,  ..., -100, -100, -100]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9815, -2.1087, -2.7903, -1.9487, -2.5880, -2.3849, 10.7188],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.logits[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'B-LOC',\n",
       " 1: 'B-PER',\n",
       " 2: 'B-TIME',\n",
       " 3: 'I-LOC',\n",
       " 4: 'I-PER',\n",
       " 5: 'I-TIME',\n",
       " 6: 'O'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics((preds.logits.detach().numpy(), tokenized_datasets['test']['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11104 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2761 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/111 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokenClassifierOutput(loss=None, logits=tensor([[[-1.1056, -2.0907, -2.6797,  ..., -2.4105, -2.3044, 10.5855],\n",
      "         [-0.9815, -2.1087, -2.7903,  ..., -2.5880, -2.3849, 10.7188],\n",
      "         [-1.2446, -2.2667, -2.6471,  ..., -2.5930, -2.2541, 10.8799],\n",
      "         ...,\n",
      "         [-1.1830, -1.8927, -2.7616,  ..., -2.4504, -2.4548, 10.6490],\n",
      "         [-1.1991, -1.9389, -2.7844,  ..., -2.3972, -2.4331, 10.6495],\n",
      "         [-1.1722, -1.9827, -2.7269,  ..., -2.4549, -2.4222, 10.6663]],\n",
      "\n",
      "        [[-1.0231, -1.9746, -2.4849,  ..., -1.9830, -2.3571,  9.8590],\n",
      "         [-1.1887, -2.3329, -2.3563,  ..., -2.5579, -2.3397, 10.5914],\n",
      "         [-1.2042, -2.5399, -2.5790,  ..., -2.5207, -2.2575, 10.8027],\n",
      "         ...,\n",
      "         [-1.1108, -1.6888, -2.7046,  ..., -2.1600, -2.7299, 10.1716],\n",
      "         [-1.0869, -1.6983, -2.7277,  ..., -2.0823, -2.7267, 10.1372],\n",
      "         [-1.0483, -1.7725, -2.6648,  ..., -2.1668, -2.7070, 10.2009]],\n",
      "\n",
      "        [[-1.0625, -2.1565, -2.7420,  ..., -2.5423, -2.1257, 10.5858],\n",
      "         [-1.1239, -2.3251, -2.6647,  ..., -2.6852, -2.0886, 10.7335],\n",
      "         [-1.1690, -2.2812, -2.8144,  ..., -2.6222, -2.0762, 10.7769],\n",
      "         ...,\n",
      "         [-1.1003, -1.9900, -2.8338,  ..., -2.5204, -2.2433, 10.5828],\n",
      "         [-1.1083, -2.0244, -2.8412,  ..., -2.4795, -2.2269, 10.5719],\n",
      "         [-1.0857, -2.0428, -2.7983,  ..., -2.5190, -2.2265, 10.5807]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1494, -1.3389, -1.6121,  ..., -1.2908, -1.2847,  7.5972],\n",
      "         [-1.7759, -2.2384, -2.5987,  ..., -2.2752, -2.3543, 10.8140],\n",
      "         [-1.8470, -1.8761, -2.4484,  ..., -2.2453, -2.2152, 10.6270],\n",
      "         ...,\n",
      "         [-1.3274, -0.7638, -2.5466,  ..., -1.6974, -3.0202,  9.3771],\n",
      "         [-1.2460, -0.8297, -2.5829,  ..., -1.6180, -2.9710,  9.2904],\n",
      "         [-1.2181, -0.7831, -2.5144,  ..., -1.6450, -3.0459,  9.3839]],\n",
      "\n",
      "        [[-1.2880, -1.1179, -1.1902,  ..., -0.9999, -0.8689,  7.0765],\n",
      "         [-1.3857, -1.7180, -1.6496,  ..., -2.8262, -2.2689, 10.7033],\n",
      "         [-1.5732, -2.7085, -1.9901,  ..., -2.5896, -2.0483, 10.9635],\n",
      "         ...,\n",
      "         [-1.4634, -0.3650, -2.7530,  ..., -1.2181, -3.1095,  9.1576],\n",
      "         [-1.3866, -0.4336, -2.7120,  ..., -1.1322, -3.0089,  9.0090],\n",
      "         [-1.3780, -0.3808, -2.7345,  ..., -1.1077, -3.1532,  9.1957]],\n",
      "\n",
      "        [[-1.2639, -1.8668, -2.0783,  ..., -1.7749, -2.0970,  9.4855],\n",
      "         [-1.4371, -2.2211, -2.3569,  ..., -2.5496, -2.1459, 10.3911],\n",
      "         [-1.6561, -2.2400, -2.6610,  ..., -2.1386, -2.0513, 10.5661],\n",
      "         ...,\n",
      "         [-1.3465, -1.6251, -2.4525,  ..., -1.9868, -2.4768, 10.0512],\n",
      "         [-1.3358, -1.6858, -2.4612,  ..., -1.8758, -2.4671,  9.9894],\n",
      "         [-1.2286, -1.6545, -2.3632,  ..., -1.9925, -2.5391, 10.0752]]],\n",
      "       grad_fn=<AddBackward0>), hidden_states=None, attentions=None)\n",
      "[[6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " ...\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]\n",
      " [6 6 6 ... 6 6 6]]\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['B-LOC', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.6419753086419753,\n",
       " 'recall': 0.06701030927835051,\n",
       " 'f1': 0.12135355892648775,\n",
       " 'classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.85      0.11      0.19       313\\n         PER       0.41      0.03      0.06       283\\n        TIME       0.50      0.06      0.10       180\\n\\n   micro avg       0.64      0.07      0.12       776\\n   macro avg       0.59      0.06      0.12       776\\nweighted avg       0.61      0.07      0.12       776\\n'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model_names['GysBERT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11104 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2761 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/111 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vprovat/anaconda3/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vprovat/anaconda3/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vprovat/anaconda3/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11104 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2761 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/111 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ee4cdb990bc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0meval_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-6a5262c9a8ce>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtoks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_collator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenized_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1765\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1767\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1768\u001b[0m         )\n\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m         )\n\u001b[1;32m   1032\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    615\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m                 )\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 538\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m         )\n\u001b[1;32m    540\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for model_name in model_names.keys():\n",
    "    model_path = model_names[model_name]\n",
    "    eval_results[model_name] = evaluate(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabi",
   "language": "python",
   "name": "tabi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
